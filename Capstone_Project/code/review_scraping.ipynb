{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd0332d9-b44e-40c0-9d99-f7a8dcc2c4c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75f33dd0-1ec3-460e-9a47-6bf2db497206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd86a63c-320a-454e-902f-f30920237f0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a934d01f-ba46-4589-90f4-7318235ced6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading merged dataset\n",
    "\n",
    "title_basics = pd.read_csv('../data/title_basics_data.tsv', sep = '\\t', low_memory=False)\n",
    "title_basics.replace('\\\\N', np.nan, inplace=True)\n",
    "title_basics = title_basics.dropna(subset=['startYear'])\n",
    "title_basics['startYear'] = title_basics['startYear'].astype('int')\n",
    "title_basics = title_basics[(title_basics['titleType']=='movie') & (title_basics['startYear']>2013)]\n",
    "\n",
    "print(title_basics.shape, title_basics['tconst'].nunique())\n",
    "\n",
    "proxy_list = pd.read_csv('./Free_Proxy_List.csv')\n",
    "\n",
    "proxy_list['full']=proxy_list['ip'].astype('string')+':'+proxy_list['port'].astype('string')\n",
    "proxies = proxy_list['full'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3a6f79-b6ea-4663-9258-4e2ae0730155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a65c9e-e37c-45f4-955a-1f319a9ed937",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if the progress file exists\n",
    "if os.path.exists(\"progress_ratings.txt\"):\n",
    "    with open(\"progress_ratings.txt\", \"r\") as file:\n",
    "        start_index = int(file.read())\n",
    "else:\n",
    "    start_index = 0\n",
    "\n",
    "# Check if the ratings data file exists\n",
    "if os.path.exists(\"df_ratings.csv\"):\n",
    "    df_ratings = pd.read_csv(\"df_ratings.csv\")\n",
    "    ratings = df_ratings[\"ratings\"].tolist()\n",
    "    films = df_ratings[\"tconst\"].tolist()\n",
    "else:\n",
    "    ratings = []\n",
    "    films = []\n",
    "\n",
    "# Scraping data from boxofficemojo.com\n",
    "new_films = title_basics['tconst'].unique()[start_index:]\n",
    "\n",
    "break_counter = 0\n",
    "\n",
    "for i, film in enumerate(new_films, start=start_index):\n",
    "    print(\"=\" * 80)\n",
    "    if break_counter == 10:\n",
    "        print(\"More than 10 bad requests\")\n",
    "        break\n",
    "\n",
    "    proxy = random.choice(proxies)\n",
    "    print(f\"Scraping for {film}\")\n",
    "    rating = get_user_ratings(film, proxy)\n",
    "    ratings.append(rating)\n",
    "    films.append(film)\n",
    "    time.sleep(random.uniform(0, 0.8))\n",
    "\n",
    "    # Save data after processing 5 films\n",
    "    if i % 5 == 0:\n",
    "        with open(\"progress_ratings.txt\", \"w\") as file:\n",
    "            file.write(str(i + 1))\n",
    "        df_ratings = pd.DataFrame({\"tconst\": films, \"ratings\": ratings})\n",
    "        df_ratings.to_csv(\"df_ratings.csv\", index=False)\n",
    "        print(\"df_ratings updated\")\n",
    "        time.sleep(random.uniform(1,3))\n",
    "\n",
    "# Remove the progress file as the processing is complete\n",
    "os.remove(\"progress_ratings.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2d38dd-3923-4497-83dd-c56fba53f1ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tconst = 'tt0000003'\n",
    "# proxy = proxies[3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0665ef0-d5e9-4e56-98ea-abed0ed2c4ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# url = f\"https://www.imdb.com/title/{tconst}/reviews\"\n",
    "\n",
    "# # List of user agent headers\n",
    "# user_agents = [\n",
    "#     \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\",\n",
    "#     \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:79.0) Gecko/20100101 Firefox/79.0\",\n",
    "#     \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.3 Safari/605.1.15\",\n",
    "#     \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36\",\n",
    "#     \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 Edg/91.0.864.59\"\n",
    "# ]\n",
    "\n",
    "\n",
    "# rating_and_username = []\n",
    "\n",
    "\n",
    "# # Get the current user agent\n",
    "# current_user_agent = user_agents[1]\n",
    "\n",
    "# # Set the headers for the request\n",
    "# headers = {\"User-Agent\": current_user_agent}\n",
    "\n",
    "# # Create a session object\n",
    "# session = requests.Session()\n",
    "\n",
    "# # Set the proxy for the session\n",
    "# session.proxies = {'http': proxy}\n",
    "\n",
    "# # Make the request using rotating proxies\n",
    "# res = session.get(url, headers=headers, timeout=5)\n",
    "\n",
    "# if res.status_code==200:\n",
    "#     print(f\"Proxy {proxy} successfully connected\")\n",
    "#     soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "\n",
    "#     chunks = re.findall(pattern = r'<div class=\"review-container\">(.*?)Was this review helpful\\?', string=str(soup), flags=re.DOTALL)\n",
    "\n",
    "#     for chunk in chunks:\n",
    "#         if \"Warning: Spoilers\" in chunk:\n",
    "#             continue\n",
    "#         else:\n",
    "#             rating_match = re.search(r'<span>(\\d{1})<\\/span><span class=\"point-scale\">', chunk)\n",
    "#             rating = rating_match.group(1) if rating_match else None\n",
    "#             if rating_match == None:\n",
    "#                 continue\n",
    "\n",
    "#             username_match = re.search(r'<span class=\"display-name-link\"><a href=\"\\/user\\/(.*?)\\?ref_=tt_urv', chunk)\n",
    "#             username = username_match.group(1).strip(\"/\") if username_match else None\n",
    "            \n",
    "#             rating_and_username.append((username, rating))\n",
    "#     print(f\"Successfully scraped: {rating_and_username}\")\n",
    "\n",
    "# else:\n",
    "#     print(print(f\"Request for {tconst} failed to execute.\"))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0833457-4019-4069-a718-9fdc832d99e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tconst = \"tt9362722\"\n",
    "# url = f\"https://www.imdb.com/title/{tconst}/reviews\"\n",
    "\n",
    "\n",
    "# proxy = \"103.127.29.105:7497\"\n",
    "\n",
    "# user_agents = [\n",
    "#         \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\",\n",
    "#         # Add more user agents here...\n",
    "#     ]\n",
    "\n",
    "# # Get the current user agent\n",
    "# current_user_agent = user_agents[0]\n",
    "\n",
    "# # Set the headers for the request\n",
    "# headers = {\"User-Agent\": current_user_agent}\n",
    "\n",
    "# session = requests.Session()\n",
    "\n",
    "# # Set the proxy for the session\n",
    "# session.proxies = {'http': proxy}\n",
    "\n",
    "# res = session.get(url, headers=headers, timeout=5)\n",
    "\n",
    "\n",
    "# soup = BeautifulSoup(res.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35db728-70a1-4244-9d28-c57905a195c6",
   "metadata": {},
   "source": [
    "1. Scrape users only who commented on all reviews\n",
    "2. Loop through each user and scrape <br>\n",
    "<font color = 'red'> Explore double-layered proxies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
